# app/main.py
import streamlit as st
import whisper
from llm_deepseek import call_llm
import tempfile
import os

st.set_page_config(page_title="AI íŠœí„° ë² íƒ€", layout="centered")
st.title("ğŸ§ ğŸ™ï¸ AI íŠœí„° ì‹¤í—˜ì‹¤")

# Whisper ëª¨ë¸ ë¡œë“œ (base ê¶Œì¥)
stt_model = whisper.load_model("base")

# ìŒì„± ì—…ë¡œë“œ
uploaded_file = st.file_uploader("ğŸ¤ ìŒì„± íŒŒì¼ ì—…ë¡œë“œ (wav/mp3)", type=["wav", "mp3"])

if uploaded_file is not None:
    st.audio(uploaded_file)

    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name

    with st.spinner("â³ ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜ ì¤‘..."):
        result = stt_model.transcribe(tmp_path, fp16=False)
        user_text = result["text"]
        os.remove(tmp_path)

    st.success("âœ… ë³€í™˜ ì™„ë£Œ")
    st.markdown(f"**ğŸ—£ï¸ ì¸ì‹ëœ ë¬¸ì¥:** `{user_text}`")

    with st.spinner("ğŸ¤– AI íŠœí„° ì‘ë‹µ ìƒì„± ì¤‘..."):
        ai_response = call_llm(user_text)
    st.markdown("---")
    st.markdown(f"**ğŸ§  íŠœí„° ì‘ë‹µ:**")
    st.info(ai_response)
